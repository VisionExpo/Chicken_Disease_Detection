{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Chicken_Disease_Detection\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Chicken_Disease_Detection'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entity = return type of function\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class DataIngestionConfig:\n",
    "    root_dir: str\n",
    "    kaggle_dataset: str\n",
    "    local_data_file: str\n",
    "    unzip_dir: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnClassifier.constants import *\n",
    "from cnnClassifier.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(self, config_path):\n",
    "        self.config = self.read_yaml(config_path)\n",
    "        # Use dictionary access to get the artifacts_root path\n",
    "        create_directories([self.config[\"artifacts_root\"]])\n",
    "\n",
    "    def read_yaml(self, file_path: Path) -> dict:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            return yaml.safe_load(file)\n",
    "\n",
    "    def get_data_ingestion_config(self):\n",
    "        # Extract the data_ingestion config section from the YAML file\n",
    "        config = self.config[\"data_ingestion\"]\n",
    "        # Ensure the directory exists for data ingestion root\n",
    "        create_directories([config[\"root_dir\"]])\n",
    "        \n",
    "        # Create and return a DataIngestionConfig object\n",
    "        data_ingestion_config = DataIngestionConfig(\n",
    "            root_dir=config[\"root_dir\"],\n",
    "            kaggle_dataset=config[\"kaggle_dataset\"],\n",
    "            local_data_file=config[\"local_data_file\"],\n",
    "            unzip_dir=config[\"unzip_dir\"]\n",
    "        )\n",
    "\n",
    "        return data_ingestion_config\n",
    "\n",
    "def create_directories(directories):\n",
    "    for directory in directories:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "import zipfile\n",
    "from cnnClassifier import logger\n",
    "from cnnClassifier.utils.common import get_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle\n",
    "import time\n",
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class DataIngestion:\n",
    "    def __init__(self, config: DataIngestionConfig):\n",
    "        self.config = config\n",
    "        self.api = KaggleApi()\n",
    "        self.api.authenticate()\n",
    "\n",
    "    def download_file(self):\n",
    "        max_retries = 3  # Maximum number of retries\n",
    "        retries = 0\n",
    "        \n",
    "        while retries < max_retries:\n",
    "            try:\n",
    "                if not os.path.exists(self.config.local_data_file):\n",
    "                    # Download the file with a progress bar\n",
    "                    url = f\"https://www.kaggle.com/api/v1/datasets/download/{self.config.kaggle_dataset}\"\n",
    "                    response = requests.get(url, stream=True)\n",
    "\n",
    "                    total_size_in_bytes = int(response.headers.get('content-length', 0))\n",
    "                    block_size = 1024  # 1 Kilobyte\n",
    "\n",
    "                    with open(self.config.local_data_file, 'wb') as file, tqdm(\n",
    "                        desc=\"Downloading\",\n",
    "                        total=total_size_in_bytes,\n",
    "                        unit='iB',\n",
    "                        unit_scale=True,\n",
    "                        unit_divisor=1024,\n",
    "                    ) as bar:\n",
    "                        for data in response.iter_content(block_size):\n",
    "                            file.write(data)\n",
    "                            bar.update(len(data))\n",
    "\n",
    "                    logger.info(f\"File downloaded to: {self.config.local_data_file}\")\n",
    "                    break  # Exit loop if download is successful\n",
    "                else:\n",
    "                    logger.info(f\"File already exists of size: {get_size(Path(self.config.local_data_file))}\")\n",
    "                break\n",
    "\n",
    "            except (requests.exceptions.RequestException, ChunkedEncodingError) as e:\n",
    "                retries += 1\n",
    "                logger.error(f\"Download failed (attempt {retries}/{max_retries}): {e}\")\n",
    "                if retries < max_retries:\n",
    "                    logger.info(f\"Retrying in 5 seconds...\")\n",
    "                    time.sleep(5)  # Delay before retrying\n",
    "                else:\n",
    "                    logger.error(\"Max retries reached. Download failed.\")\n",
    "                    raise e\n",
    "\n",
    "    def get_size(self, file_path):\n",
    "        # Get the size of the file\n",
    "        size = os.path.getsize(file_path)\n",
    "        return f\"{size / (1024 * 1024):.2f} MB\"\n",
    "\n",
    "    def extract_zip_file(self):\n",
    "        \"\"\"\n",
    "        Extracts the zip file into the data directory with a progress bar.\n",
    "        \"\"\"\n",
    "        unzip_path = self.config.unzip_dir\n",
    "        os.makedirs(unzip_path, exist_ok=True)\n",
    "\n",
    "        # Check if the downloaded file is a ZIP\n",
    "        if not self.config.local_data_file.endswith('.zip'):\n",
    "            logger.error(\"The downloaded file is not a ZIP file. Cannot extract.\")\n",
    "            return\n",
    "\n",
    "        # Check if the ZIP file exists\n",
    "        if not os.path.exists(self.config.local_data_file):\n",
    "            logger.error(\"ZIP file not found. Cannot extract.\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            # Verify if it's a valid ZIP file\n",
    "            with zipfile.ZipFile(self.config.local_data_file, 'r') as zip_ref:\n",
    "                # If no exception is raised, it's a valid ZIP file\n",
    "                total_files = len(zip_ref.infolist())\n",
    "\n",
    "                # Use tqdm to display a progress bar for the extraction\n",
    "                for member in tqdm(zip_ref.infolist(), desc=\"Extracting\", total=total_files):\n",
    "                    zip_ref.extract(member, unzip_path)\n",
    "                \n",
    "            logger.info(f\"ZIP file extracted successfully to: {unzip_path}\")\n",
    "        \n",
    "        except zipfile.BadZipFile:\n",
    "            logger.error(\"The file is not a valid ZIP file or is corrupted.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"An error occurred while extracting the ZIP file: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 7.90G/7.90G [21:11<00:00, 6.67MiB/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-06 10:37:41,777: INFO: 1521902571: File downloaded to: artifacts/data_ingestion/data.zip]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting: 100%|██████████| 6812/6812 [00:31<00:00, 215.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-06 10:38:13,414: INFO: 1521902571: ZIP file extracted successfully to: artifacts/data_ingestion]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    try:\n",
    "        # Initialize Configuration Manager\n",
    "        config_manager = ConfigurationManager(config_path=CONFIG_FILE_PATH)\n",
    "        \n",
    "        # Get Data Ingestion Configuration\n",
    "        data_ingestion_config = config_manager.get_data_ingestion_config()\n",
    "        \n",
    "        # Create DataIngestion object and download/extract data\n",
    "        data_ingestion = DataIngestion(config=data_ingestion_config)\n",
    "        data_ingestion.download_file()\n",
    "        data_ingestion.extract_zip_file()\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise e\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chicken",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
